def drop_correlated_features(df, threshold):
    '''
    Define a function that drops features that are highly correlated with each other
    The threshold is the correlation value above which a feature is considered highly correlated.
    Return a list of the columns names that should be dropped
    '''
    #Generated by ChatGPT
    corr_matrix = df.corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]
    return to_drop

def add_polynomical_features(df,degree):
    '''
    Define a function that adds polynomial features to the dataframe
    For each feature in the dataframe, adding n-1 features that are the power of 2 to n of the original feature
    (n is the number of degrees)
    '''
    for column in df.columns:
        if column in ['Cr', 'Co', 'Ti', 'Zr']:
                for i in range(2,degree+1):
                    df[column+'^'+str(i)] = df[column]**i
    return df


def regmodel_param_plot(
    validation_score, train_score, alphas_to_try, chosen_alpha,
    scoring, model_name, test_score = None, filename = None):

    plt.figure(figsize = (8,8))
    sns.lineplot(y = validation_score, x = alphas_to_try,
                 label = 'validation_data')
    sns.lineplot(y = train_score, x = alphas_to_try,
                 label = 'training_data')
    plt.axvline(x=chosen_alpha, linestyle='--')
    if test_score is not None:
        sns.lineplot(y = test_score, x = alphas_to_try,
                     label = 'test_data')
    plt.xlabel('alpha_parameter')
    plt.ylabel(scoring)
    #set log scale
    #plt.xscale('log')
    plt.title(model_name + ' Regularisation')
    plt.legend()
    #------------------------

    #------------------------

    if filename is not None:
        plt.savefig(str(filename) + ".png")



def regmodel_param_test(
    alphas_to_try, X, y, cv, scoring = 'r2',
    model_name = 'LASSO', X_test = None, y_test = None,
    draw_plot = False, filename = None):

    validation_scores = []
    train_scores = []
    results_list = []
    if X_test is not None:
        test_scores = []
        scorer = get_scorer(scoring)
    else:
        test_scores = None

    for curr_alpha in alphas_to_try:

        if model_name == 'LASSO':
            regmodel = Lasso(alpha = curr_alpha)
        elif model_name == 'Ridge':
            regmodel = Ridge(alpha = curr_alpha)
        else:
            return None

        results = cross_validate(
            regmodel, X, y, scoring=scoring, cv=cv,
            return_train_score = True)

        validation_scores.append(np.mean(results['test_score']))
        train_scores.append(np.mean(results['train_score']))
        results_list.append(results)

        if X_test is not None:
            regmodel.fit(X,y)
            y_pred = regmodel.predict(X_test)
            test_scores.append(scorer(regmodel, X_test, y_test))

    chosen_alpha_id = np.argmax(validation_scores)
    chosen_alpha = alphas_to_try[chosen_alpha_id]
    max_validation_score = np.max(validation_scores)
    if X_test is not None:
        test_score_at_chosen_alpha = test_scores[chosen_alpha_id]
    else:
        test_score_at_chosen_alpha = None

    if draw_plot:
        regmodel_param_plot(
            validation_scores, train_scores, alphas_to_try, chosen_alpha,
            scoring, model_name, test_scores, filename)

    return chosen_alpha, max_validation_score, test_score_at_chosen_alpha


#%%
def random_cv(mat_X,mat_y,n_split=5):

    kf = KFold(n_splits=n_split, shuffle=True)
    #mat_X = mat_X.to_numpy()
    #mat_y = mat_y.to_numpy()

    random_list = []
    for train_index, test_index in kf.split(mat_X):
        X_train, X_test = mat_X.loc[train_index], mat_X.loc[test_index]
        y_train, y_test = mat_y.loc[train_index], mat_y.loc[test_index]

        sc = StandardScaler()
        sc.fit(X_train)
        mat_X_train = sc.transform(X_train)
        mat_X_test = sc.transform(X_test)

        # KNN.fit(X_train, y_train)
        # y_pred = KNN.predict(X_test)

        random_list.append([train_index, test_index, X_train, X_test, y_train, y_test])

    return random_list